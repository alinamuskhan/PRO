{
  "metadata": {
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# **Decision Tree Algorithm**",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "A **decision tree** is a supervised machine learning algorithm used for **classification** and **regression tasks**. It splits the data into subsets based on the value of input features, creating a tree-like structure of decisions.\n\n### Key Components:\n- **Nodes**: Represent decisions or tests on a feature.\n- **Root Node**: The top node, where the first decision is made.\n- **Leaf Nodes**: The final outcome, representing **class labels** (in classification) or **values** (in regression).\n- **Branches**: The paths connecting nodes, representing outcomes of decisions.\n\nThe algorithm works by selecting the best feature to split the data at each node using criteria like **Gini Impurity** (for classification) or **Mean Squared Error** (for regression). This process repeats recursively until a stopping condition is met, such as reaching a **maximum tree depth** or having **pure nodes**.\n\n![DT](https://images.spiceworks.com/wp-content/uploads/2022/05/04131724/How-does-a-decision-tree-work.png)\n\n### Advantages:\n- **Interpretability**: Decision trees are easy to interpret and visualize.\n- Can handle both **numerical** and **categorical data**.\n\nHowever, decision trees are prone to **overfitting**, especially when the tree is deep. They may also be **unstable**, with small changes in the data leading to drastically different trees. **Pruning** (removing unnecessary branches) helps mitigate overfitting.\n\n### Additional Details:\n\n- **Building the Tree**: The tree is built by iteratively splitting the data at each node based on a feature that best separates the target variable. The best feature is chosen using metrics like **Gini Impurity**, **Information Gain** (for classification), or **Mean Squared Error** (for regression).\n  \n- **Overfitting and Pruning**: Decision trees can become overly complex and perform well on training data but poorly on unseen data (overfitting). To address this, **pruning** techniques like **cost complexity pruning** or **post-pruning** remove branches that don't significantly improve accuracy.\n\n- **Advantages Over Other Models**: Decision trees are **non-parametric**, meaning they do not assume a specific form for the data distribution. They are also easy to interpret and visualize, which is beneficial for explaining the decision-making process.\n\n- **Disadvantages**: Despite their interpretability, decision trees are sensitive to **noisy data** and can easily become too complex. They may also be biased towards features with more categories, and their performance can degrade with an increase in the number of features. **Ensemble methods** like **Random Forests** and **Gradient Boosting Trees** mitigate these issues by combining multiple trees to improve generalization.\n\n### Next Steps in the Decision Tree Process\n\nAfter understanding the key concepts, advantages, and challenges associated with decision trees, we can proceed with the **practical implementation**. The next steps involve:\n\n- **Preparing the dataset** (e.g., cleaning, encoding)\n- **Configuring the model** (e.g., setting hyperparameters)\n- **Training** the decision tree\n- **Evaluating** its performance\n\nThese steps are critical to ensure the decision tree is effectively built and performs well on unseen data. We will begin by obtaining and pre-processing the data, followed by model training, prediction, and evaluation.\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#Importing the libraries\nimport pandas as pd\nimport numpy as np",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 24
    },
    {
      "cell_type": "code",
      "source": "# Installing seaborn (this step may not be necessary if seaborn is already installed)\nimport piplite\nawait piplite.install(\"seaborn\")\n\n# Importing the necessary libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Displaying plots inline in Jupyter/Colab notebooks\n%matplotlib inline",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 25
    },
    {
      "cell_type": "code",
      "source": "#importing warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 26
    },
    {
      "cell_type": "markdown",
      "source": "### About the Dataset\n\nThis dataset contains information about a set of patients who suffered from the same illness. During their treatment, each patient was prescribed one of five medications: **Drug A**, **Drug B**, **Drug C**, **Drug X**, or **Drug Y**. The goal is to build a model to predict which drug a future patient might respond to based on various features.\n\nThe features in the dataset are:\n- **Age**: The age of the patient.\n- **Sex**: The gender of the patient (male or female).\n- **Blood Pressure (BP)**: The patient's blood pressure level.\n- **Cholesterol**: The cholesterol level of the patient.\n- **Na_to_K**: The sodium-to-potassium ratio in the patient's body.\n\nThe target variable is the **Drug**, which represents the medication that each patient responded to. This is a **multiclass classification** problem, where the objective is to classify the drug that a new or unknown patient would be prescribed, based on the features.\n\nThe dataset is useful for building a decision tree model that can predict the appropriate drug for a new patient based on their characteristics.\n\n\nNow, read the data using pandas dataframe:\n",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Reading the Dataset\ndf=pd.read_csv(\"drug200.csv\",delimiter=\",\")",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 27
    },
    {
      "cell_type": "code",
      "source": "# The following command displays the first 10 rows of the DataFrame 'df'\n# It is useful to quickly inspect the data and check its structure, columns, and values.\n\ndf.head(10) # Showing the first 10 rows of the DataFrame 'df'",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 28,
          "output_type": "execute_result",
          "data": {
            "text/plain": "   Age Sex      BP Cholesterol  Na_to_K   Drug\n0   23   F    HIGH        HIGH   25.355  drugY\n1   47   M     LOW        HIGH   13.093  drugC\n2   47   M     LOW        HIGH   10.114  drugC\n3   28   F  NORMAL        HIGH    7.798  drugX\n4   61   F     LOW        HIGH   18.043  drugY\n5   22   F  NORMAL        HIGH    8.607  drugX\n6   49   F  NORMAL        HIGH   16.275  drugY\n7   41   M     LOW        HIGH   11.037  drugC\n8   60   M  NORMAL        HIGH   15.171  drugY\n9   43   M     LOW      NORMAL   19.368  drugY",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Sex</th>\n      <th>BP</th>\n      <th>Cholesterol</th>\n      <th>Na_to_K</th>\n      <th>Drug</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>23</td>\n      <td>F</td>\n      <td>HIGH</td>\n      <td>HIGH</td>\n      <td>25.355</td>\n      <td>drugY</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>47</td>\n      <td>M</td>\n      <td>LOW</td>\n      <td>HIGH</td>\n      <td>13.093</td>\n      <td>drugC</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>47</td>\n      <td>M</td>\n      <td>LOW</td>\n      <td>HIGH</td>\n      <td>10.114</td>\n      <td>drugC</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>28</td>\n      <td>F</td>\n      <td>NORMAL</td>\n      <td>HIGH</td>\n      <td>7.798</td>\n      <td>drugX</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>61</td>\n      <td>F</td>\n      <td>LOW</td>\n      <td>HIGH</td>\n      <td>18.043</td>\n      <td>drugY</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>22</td>\n      <td>F</td>\n      <td>NORMAL</td>\n      <td>HIGH</td>\n      <td>8.607</td>\n      <td>drugX</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>49</td>\n      <td>F</td>\n      <td>NORMAL</td>\n      <td>HIGH</td>\n      <td>16.275</td>\n      <td>drugY</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>41</td>\n      <td>M</td>\n      <td>LOW</td>\n      <td>HIGH</td>\n      <td>11.037</td>\n      <td>drugC</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>60</td>\n      <td>M</td>\n      <td>NORMAL</td>\n      <td>HIGH</td>\n      <td>15.171</td>\n      <td>drugY</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>43</td>\n      <td>M</td>\n      <td>LOW</td>\n      <td>NORMAL</td>\n      <td>19.368</td>\n      <td>drugY</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 28
    },
    {
      "cell_type": "code",
      "source": "# The following command returns the number of rows and columns in the DataFrame 'df'.\n# It is useful to quickly check the size of your dataset.\n\ndf.shape  # Returns a tuple (number_of_rows, number_of_columns)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 29,
          "output_type": "execute_result",
          "data": {
            "text/plain": "(200, 6)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 29
    },
    {
      "cell_type": "code",
      "source": "# The following command generates descriptive statistics for all the numerical columns in the DataFrame 'df'\n# It helps you quickly summarize the distribution and central tendency of the data.\n\ndf.describe()  # Returns summary statistics for numerical columns in the DataFrame",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 30,
          "output_type": "execute_result",
          "data": {
            "text/plain": "              Age     Na_to_K\ncount  200.000000  200.000000\nmean    44.315000   16.084485\nstd     16.544315    7.223956\nmin     15.000000    6.269000\n25%     31.000000   10.445500\n50%     45.000000   13.936500\n75%     58.000000   19.380000\nmax     74.000000   38.247000",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Age</th>\n      <th>Na_to_K</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>200.000000</td>\n      <td>200.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>44.315000</td>\n      <td>16.084485</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>16.544315</td>\n      <td>7.223956</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>15.000000</td>\n      <td>6.269000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>31.000000</td>\n      <td>10.445500</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>45.000000</td>\n      <td>13.936500</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>58.000000</td>\n      <td>19.380000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>74.000000</td>\n      <td>38.247000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 30
    },
    {
      "cell_type": "code",
      "source": "# The following command provides a summary of the DataFrame 'df'.\n# It includes the column names, data types, and the number of non-null entries for each column.\n\ndf.info()  # Returns a summary of the DataFrame, including column data types and non-null counts",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 200 entries, 0 to 199\nData columns (total 6 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   Age          200 non-null    int64  \n 1   Sex          200 non-null    object \n 2   BP           200 non-null    object \n 3   Cholesterol  200 non-null    object \n 4   Na_to_K      200 non-null    float64\n 5   Drug         200 non-null    object \ndtypes: float64(1), int64(1), object(4)\nmemory usage: 6.3+ KB\n",
          "output_type": "stream"
        }
      ],
      "execution_count": 31
    },
    {
      "cell_type": "markdown",
      "source": "### Pre-processing\n\nUsing **my_data** as the Drug.csv data read by pandas, declare the following variables:\n\n- **X** as the Feature Matrix (data of **my_data**)\n- **y** as the response vector (target)\n\nRemove the column containing the target name since it doesn't contain numeric values.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Declaring the feature matrix (X) and response vector (y)\nX = df[['Age', 'Sex', 'BP', 'Cholesterol', 'Na_to_K']].values  # Selecting relevant features\ny = df['Drug']  # The target variable 'Drug'",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": 41
    },
    {
      "cell_type": "code",
      "source": "# X contains the selected features \nX[0:5]",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 47,
          "output_type": "execute_result",
          "data": {
            "text/plain": "array([[23, 'F', 'HIGH', 'HIGH', 25.355],\n       [47, 'M', 'LOW', 'HIGH', 13.093],\n       [47, 'M', 'LOW', 'HIGH', 10.114],\n       [28, 'F', 'NORMAL', 'HIGH', 7.798],\n       [61, 'F', 'LOW', 'HIGH', 18.043]], dtype=object)"
          },
          "metadata": {}
        }
      ],
      "execution_count": 47
    },
    {
      "cell_type": "code",
      "source": "# Importing preprocessing from sklearn\nfrom sklearn import preprocessing\n\n# Encoding the 'Sex' feature (F = 0, M = 1)\ndf_sex = preprocessing.LabelEncoder()\ndf_sex.fit(['F','M'])\nX[:,1] = le_sex.transform(X[:,1]) # Transforming the 'Sex' column in the feature matrix\n\n# Encoding the 'Blood Pressure' feature (LOW = 0, NORMAL = 1, HIGH = 2)\ndf_BP = preprocessing.LabelEncoder()\ndf_BP.fit([ 'LOW', 'NORMAL', 'HIGH'])\nX[:,2] = le_BP.transform(X[:,2]) # Transforming the 'BP' column in the feature matrix\n\n# Encoding the 'Cholesterol' feature (NORMAL = 0, HIGH = 1)\ndf_Chol = preprocessing.LabelEncoder()\ndf_Chol.fit([ 'NORMAL', 'HIGH'])\nX[:,3] = le_Chol.transform(X[:,3]) # Transforming the 'Cholesterol' column in the feature matrix\n\n# Displaying the first 5 rows of the feature matrix after encoding\nX[0:5]",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": "Now we can fill the target variable.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "#y contains the target (drug class)\ny[0:5]",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "execution_count": 44,
          "output_type": "execute_result",
          "data": {
            "text/plain": "0    drugY\n1    drugC\n2    drugC\n3    drugX\n4    drugY\nName: Drug, dtype: object"
          },
          "metadata": {}
        }
      ],
      "execution_count": 44
    },
    {
      "cell_type": "markdown",
      "source": "As you may figure out, some features in this dataset are categorical, such as **Sex** or **BP**. Unfortunately, Sklearn Decision Trees does not handle categorical variables. We can still convert these features to numerical values using **pandas.get_dummies()**| to convert the categorical variable into dummy/indicator variables.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "### Setting up the Decision Tree\n\nTo build and evaluate our decision tree model, we need to split the dataset into a **training set** and a **testing set**. This allows us to train the model on one portion of the data and evaluate its performance on another, unseen portion. We will use the **train_test_split** function from the **sklearn.model_selection** library to perform this split.\n\nA common practice is to allocate **70%** of the data to the training set and **30%** to the testing set. This ensures the model has enough data to learn from while also providing a fair evaluation using the test set.",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# Importing train_test_split from sklearn\nfrom sklearn.model_selection import train_test_split\n\n# Splitting the data into training and testing sets\nX_train,X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 3)\n\n# Print the shape of the training and test sets\nprint ('Train set:', X_train.shape,  y_train.shape)\nprint ('Test set:', X_test.shape,  y_test.shape)",
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "ename": "<class 'NameError'>",
          "evalue": "name 'X' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[2], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Splitting the data into training and testing sets\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m X_train,X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[43mX\u001b[49m, y, test_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.3\u001b[39m, random_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Print the shape of the training and test sets\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain set:\u001b[39m\u001b[38;5;124m'\u001b[39m, X_train\u001b[38;5;241m.\u001b[39mshape,  y_train\u001b[38;5;241m.\u001b[39mshape)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ],
          "output_type": "error"
        }
      ],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": "",
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}